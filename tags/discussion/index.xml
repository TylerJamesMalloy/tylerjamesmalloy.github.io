<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>discussion on Human and Machine Learning in Cognitive Science</title><link>tylerjamesmalloy.github.io/tags/discussion/</link><description>Recent content in discussion on Human and Machine Learning in Cognitive Science</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>&lt;a href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank" rel="noopener">CC BY-NC 4.0&lt;/a></copyright><lastBuildDate>Wed, 05 Apr 2023 00:00:00 +0000</lastBuildDate><atom:link href="tylerjamesmalloy.github.io/tags/discussion/index.xml" rel="self" type="application/rss+xml"/><item><title>Job Security</title><link>tylerjamesmalloy.github.io/posts/job-security/</link><pubDate>Wed, 05 Apr 2023 00:00:00 +0000</pubDate><guid>tylerjamesmalloy.github.io/posts/job-security/</guid><description>I recently completed the last meeting with a small group of mentees from my alma mater UBC that was put together to give undergraduate students at different points in their career some insight into life after undergrad. I think it was a great experience for myself, as I had little previous work as a direct mentor, and hopefully the mentees felt the same way. The remainder of this blog post is some reflections from my experience as a mentor and the life lessons I have thought of and tried to discuss with them.</description></item><item><title>What's in a Representation?</title><link>tylerjamesmalloy.github.io/posts/whats-in-a-representation/</link><pubDate>Mon, 29 Aug 2022 00:00:00 +0000</pubDate><guid>tylerjamesmalloy.github.io/posts/whats-in-a-representation/</guid><description>As I begin the final stages of my PhD thesis, I was recently surprised by one topic that jumped out as being more relevant than I had originally thought of when I began work on the project. Broadly, the topic is in the realm of cognitive modelling, specifcially modelling and predicting the behaviour of humans performing a learning and decision making task based on visual information. Traditional approaches to predicting how humans learn and make desicions have done so by abstracting away much of the compelxity of the task presented to humans, and modelling their behaviour as some simple function of the features of the task, such as a soft-max distribution over the utilities associated with the options presented.</description></item><item><title>Beyond Reward</title><link>tylerjamesmalloy.github.io/posts/beyond-reward/</link><pubDate>Thu, 07 Apr 2022 00:00:00 +0000</pubDate><guid>tylerjamesmalloy.github.io/posts/beyond-reward/</guid><description>In a previous post I mentioned an interesting paper that made the claim that much of human intelligence could be viewed under the lense of reward maximization, you can see that blog post here. This point of view may not be the most common among either psychologists or computer scientists, but it would be great news for reinforcement learning researchers who are interested in making very smart systems by training them to maximize reward.</description></item><item><title>Rl Web Security</title><link>tylerjamesmalloy.github.io/posts/rl-web-security/</link><pubDate>Sat, 05 Mar 2022 00:00:00 +0000</pubDate><guid>tylerjamesmalloy.github.io/posts/rl-web-security/</guid><description>Since my partner is a web security expert, I often end up having long discussions about internet security, even though my personal knowledge and research is in a very different area. That has recently gotten us to thinking about the intersection of reinforcement learning and web security. Though at first these may seem like two disparate areas, as anyone who has had experience talking at length with another person about their specific research area will know, eventually there are many commonalities that can be found between the two.</description></item><item><title>Wordl Rl</title><link>tylerjamesmalloy.github.io/posts/wordl-rl/</link><pubDate>Thu, 03 Feb 2022 00:00:00 +0000</pubDate><guid>tylerjamesmalloy.github.io/posts/wordl-rl/</guid><description>This post will discuss briefly the possiblity of constucting a reinforcement learning algorithm to play the game Wordle. Language based applications of reinforcement learning are somewhat common, though perhaps not the first thing RL researchers think of as examples of applications in RL. However, Wordle is a single player game with a discrete number of actions and states, the proverbial bread and butter of RL algorithms such as one of the first successful game players TD-gammon, which palyed backgammon.</description></item></channel></rss>