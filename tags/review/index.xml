<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Review on Human and Machine Learning in Cognitive Science</title><link>tylerjamesmalloy.github.io/tags/review/</link><description>Recent content in Review on Human and Machine Learning in Cognitive Science</description><generator>Hugo</generator><language>en</language><copyright>&lt;a href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank" rel="noopener">CC BY-NC 4.0&lt;/a></copyright><lastBuildDate>Tue, 24 Jan 2023 00:00:00 +0000</lastBuildDate><atom:link href="tylerjamesmalloy.github.io/tags/review/index.xml" rel="self" type="application/rss+xml"/><item><title>Sentience and World Representations in LLMs</title><link>tylerjamesmalloy.github.io/posts/sentience/</link><pubDate>Tue, 24 Jan 2023 00:00:00 +0000</pubDate><guid>tylerjamesmalloy.github.io/posts/sentience/</guid><description>In my last blog post I discussed a few of the presentations given at NeurIPS 2022 that I found particularly interesting. I didn&amp;rsquo;t get a chance to write much on another presentation given by David Chalmers that was a condensed version of his earlier talk &amp;ldquo;Are Large Language Models Sentient?&amp;rdquo;. In this talk Chalmers discussed several possible positions on the question of sentience in large language models, systematically looking how these positions would define sentience and whether or not it is possible for LLMs like ChatGPT to exhibit those properties.</description></item><item><title>Is Reward Enough</title><link>tylerjamesmalloy.github.io/posts/is-reward-enough/</link><pubDate>Mon, 17 Jan 2022 00:00:00 +0000</pubDate><guid>tylerjamesmalloy.github.io/posts/is-reward-enough/</guid><description>In this post I provide a review and opinion on the paper &amp;ldquo;Reward Is Enough&amp;rdquo; by D Silver, S Singh, D Precup, and RS Sutton. In this work, the authors provide a broad perspective on reinforcement learning research and put forward the opinion that much of the behavior that interests cognitive science and artificial intelligence researchers can be viewed in relation to reward. Specifically, they propose that many cognitive faculties such as perception, language, generalization, imitation, and even general intelligence can be achieved through reward maximization and experience in an environment.</description></item></channel></rss>