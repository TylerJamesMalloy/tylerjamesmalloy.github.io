<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Human and Machine Learning in Cognitive Science</title><link>tylerjamesmalloy.github.io/</link><description>Recent content on Human and Machine Learning in Cognitive Science</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>&lt;a href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank" rel="noopener">CC BY-NC 4.0&lt;/a></copyright><lastBuildDate>Wed, 05 Apr 2023 00:00:00 +0000</lastBuildDate><atom:link href="tylerjamesmalloy.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>Job Security</title><link>tylerjamesmalloy.github.io/posts/job-security/</link><pubDate>Wed, 05 Apr 2023 00:00:00 +0000</pubDate><guid>tylerjamesmalloy.github.io/posts/job-security/</guid><description>I recently completed the last meeting with a small group of mentees from my alma mater UBC that was put together to give undergraduate students at different points in their career some insight into life after undergrad. I think it was a great experience for myself, as I had little previous work as a direct mentor, and hopefully the mentees felt the same way. The remainder of this blog post is some reflections from my experience as a mentor and the life lessons I have thought of and tried to discuss with them.</description></item><item><title>Narrowing The Gap With LLMs</title><link>tylerjamesmalloy.github.io/posts/narrowing-gap/</link><pubDate>Tue, 14 Feb 2023 00:00:00 +0000</pubDate><guid>tylerjamesmalloy.github.io/posts/narrowing-gap/</guid><description>This will be my third blog post in a row (see the first, and second) on the topic of large language models. While this area of research has been in the news significantly recently, it is not exactly my area. However, there was a talk at the University of Pittsburgh philosophy department given by professor Colin Allen that was, at least partially, presented as a refutation to the position of David Chalmers that I discussed previously.</description></item><item><title>Sentience and World Representations in LLMs</title><link>tylerjamesmalloy.github.io/posts/sentience/</link><pubDate>Tue, 24 Jan 2023 00:00:00 +0000</pubDate><guid>tylerjamesmalloy.github.io/posts/sentience/</guid><description>In my last blog post I discussed a few of the presentations given at NeurIPS 2022 that I found particularly interesting. I didn&amp;rsquo;t get a chance to write much on another presentation given by David Chalmers that was a condensed version of his earlier talk &amp;ldquo;Are Large Language Models Sentient?&amp;rdquo;. In this talk Chalmers discussed several possible positions on the question of sentience in large language models, systematically looking how these positions would define sentience and whether or not it is possible for LLMs like ChatGPT to exhibit those properties.</description></item><item><title>NeurIPS 2022</title><link>tylerjamesmalloy.github.io/posts/neurips-2022/</link><pubDate>Mon, 05 Dec 2022 00:00:00 +0000</pubDate><guid>tylerjamesmalloy.github.io/posts/neurips-2022/</guid><description>This year I attended the Conference on Neural Information Processing Systems for the first time to present a poster alongside a paper that was accepted at the workshop on Information Theoretic Principles in Cognitive Systems.
The first day fo the conference I attended the NewInML workshop, which was intended for researchers that are new to the machine learning community. Since this was my first NeurIPS and my background is in cognitive science, this felt like the perfect way to start the conference.</description></item><item><title>PhD Defense</title><link>tylerjamesmalloy.github.io/posts/phd-defense/</link><pubDate>Thu, 10 Nov 2022 00:00:00 +0000</pubDate><guid>tylerjamesmalloy.github.io/posts/phd-defense/</guid><description>It has been a while since I made a blog post, mostly becase I have been working hard on my PhD Dissertation and practicing for my defense, which you can watch a practice run through of at this link. Since the last time I made a post I have defended my dissertation and I am now in the final stages of my work at Rensselaer. I have had an amazing time working at RPI with my mentor Chris R.</description></item><item><title>About Me</title><link>tylerjamesmalloy.github.io/about/</link><pubDate>Mon, 29 Aug 2022 12:55:28 -0400</pubDate><guid>tylerjamesmalloy.github.io/about/</guid><description>About Me! My name is Tyler Malloy. I am currently a postdoctoral researcher at Carnegie Mellon University in Pittsburgh PA. Prior to working at CMU I recieved my PhD in Cognitive Science from Rensselaer Polytechnic Institute under the advisment of Chris R. Sims. In my current position, as during my degree, I study human and machine learning. One part of my research is in cognitive modelling, studying how humans learn and make decisions, particularly how they represent visual information while achieving these goals.</description></item><item><title>Projects</title><link>tylerjamesmalloy.github.io/projects/</link><pubDate>Mon, 29 Aug 2022 12:55:28 -0400</pubDate><guid>tylerjamesmalloy.github.io/projects/</guid><description>Stay tuned for links and descriptions of my past and current projects!</description></item><item><title>What's in a Representation?</title><link>tylerjamesmalloy.github.io/posts/whats-in-a-representation/</link><pubDate>Mon, 29 Aug 2022 00:00:00 +0000</pubDate><guid>tylerjamesmalloy.github.io/posts/whats-in-a-representation/</guid><description>As I begin the final stages of my PhD thesis, I was recently surprised by one topic that jumped out as being more relevant than I had originally thought of when I began work on the project. Broadly, the topic is in the realm of cognitive modelling, specifcially modelling and predicting the behaviour of humans performing a learning and decision making task based on visual information. Traditional approaches to predicting how humans learn and make desicions have done so by abstracting away much of the compelxity of the task presented to humans, and modelling their behaviour as some simple function of the features of the task, such as a soft-max distribution over the utilities associated with the options presented.</description></item><item><title>Vss 2022</title><link>tylerjamesmalloy.github.io/posts/vss-2022/</link><pubDate>Sat, 28 May 2022 00:00:00 +0000</pubDate><guid>tylerjamesmalloy.github.io/posts/vss-2022/</guid><description>Earlier this month I attented the Visual Science Society 2022 conference where I gave a talk titled &amp;ldquo;A Beta-Variational Auto-Encoder Model of Human Visual Representation Formation in Utility-Based Learning&amp;rdquo;. The entire abstract I submitted is copied at the bottom of this blog post if you would like to read it.
The VSS experience was very positive, I was somewhat worried or hesitant that I would not get a lot of the posters and talks since my experience is much more in the learning domain rather than vision.</description></item><item><title>Beyond Reward</title><link>tylerjamesmalloy.github.io/posts/beyond-reward/</link><pubDate>Thu, 07 Apr 2022 00:00:00 +0000</pubDate><guid>tylerjamesmalloy.github.io/posts/beyond-reward/</guid><description>In a previous post I mentioned an interesting paper that made the claim that much of human intelligence could be viewed under the lense of reward maximization, you can see that blog post here. This point of view may not be the most common among either psychologists or computer scientists, but it would be great news for reinforcement learning researchers who are interested in making very smart systems by training them to maximize reward.</description></item><item><title>Rl Web Security</title><link>tylerjamesmalloy.github.io/posts/rl-web-security/</link><pubDate>Sat, 05 Mar 2022 00:00:00 +0000</pubDate><guid>tylerjamesmalloy.github.io/posts/rl-web-security/</guid><description>Since my partner is a web security expert, I often end up having long discussions about internet security, even though my personal knowledge and research is in a very different area. That has recently gotten us to thinking about the intersection of reinforcement learning and web security. Though at first these may seem like two disparate areas, as anyone who has had experience talking at length with another person about their specific research area will know, eventually there are many commonalities that can be found between the two.</description></item><item><title>Wordl Rl</title><link>tylerjamesmalloy.github.io/posts/wordl-rl/</link><pubDate>Thu, 03 Feb 2022 00:00:00 +0000</pubDate><guid>tylerjamesmalloy.github.io/posts/wordl-rl/</guid><description>This post will discuss briefly the possiblity of constucting a reinforcement learning algorithm to play the game Wordle. Language based applications of reinforcement learning are somewhat common, though perhaps not the first thing RL researchers think of as examples of applications in RL. However, Wordle is a single player game with a discrete number of actions and states, the proverbial bread and butter of RL algorithms such as one of the first successful game players TD-gammon, which palyed backgammon.</description></item><item><title>Is Reward Enough</title><link>tylerjamesmalloy.github.io/posts/is-reward-enough/</link><pubDate>Mon, 17 Jan 2022 00:00:00 +0000</pubDate><guid>tylerjamesmalloy.github.io/posts/is-reward-enough/</guid><description>In this post I provide a review and opinion on the paper &amp;ldquo;Reward Is Enough&amp;rdquo; by D Silver, S Singh, D Precup, and RS Sutton. In this work, the authors provide a broad perspective on reinforcement learning research and put forward the opinion that much of the behavior that interests cognitive science and artificial intelligence researchers can be viewed in relation to reward. Specifically, they propose that many cognitive faculties such as perception, language, generalization, imitation, and even general intelligence can be achieved through reward maximization and experience in an environment.</description></item><item><title>Masters Thesis 2020</title><link>tylerjamesmalloy.github.io/posts/masters-thesis-2020/</link><pubDate>Tue, 28 Dec 2021 00:00:00 +0000</pubDate><guid>tylerjamesmalloy.github.io/posts/masters-thesis-2020/</guid><description>This post is another retrospective, but instead of a conference or journal paper it takes a look at my masters thesis, titled &amp;ldquo;Modelling Learning and Decision Making Under Information Processing Constraints&amp;rdquo;. This blog post will go through the begninning stages of the project and how it ultimately narrowed down the focus of the thesis and project into what it eventually became.
Very early on in my PhD, I became interested my advisor Chris Sims&amp;rsquo; previous work using infromation theory, specifically mutual information, as a tool to understand the cognitive costs of behaviour in learning and decision making tasks.</description></item><item><title>AAAI 2021</title><link>tylerjamesmalloy.github.io/posts/aaai-2021/</link><pubDate>Sun, 26 Dec 2021 00:00:00 +0000</pubDate><guid>tylerjamesmalloy.github.io/posts/aaai-2021/</guid><description>This is the second post in a series of retrospectives on previous work I have done that shaped my PhD and are related to my future research goals. If you would like to read the paper you can find it on my Researchgate.
Although this paper is relatively recent, I thought I would use it as my second post because it is closely realted to a project that I began soon after beginning my AI Researcher position with IBM in early 2019.</description></item><item><title>Predicting Human Choice</title><link>tylerjamesmalloy.github.io/posts/predicting-human-choice/</link><pubDate>Wed, 15 Dec 2021 00:00:00 +0000</pubDate><guid>tylerjamesmalloy.github.io/posts/predicting-human-choice/</guid><description>This is the first post in a series of retrospectives looking back at papers and conferences I have attended. Now that I am entering my final year of my PhD, I will be begining this as a chronicle of projects, papers and conferences that influenced my time during my PhD.
This was my first accepted paper, I submitted it to the conference Reinforcement Learning and Decision Making in 2019. I attended the conference which was a great experience.</description></item><item><title>New Year 2022</title><link>tylerjamesmalloy.github.io/posts/new-year-2022/</link><pubDate>Sun, 03 Jan 2021 00:00:00 +0000</pubDate><guid>tylerjamesmalloy.github.io/posts/new-year-2022/</guid><description>Rather than look back at previous research I have done, as the previous posts on this blog have done, this post will look forward to my hopes for 2022 and new research ideas I am interested in. Firstly, the major plans for this year include completing the website hosting my thesis project, submitting a paper based on my work in Theory of Mind for reinforcement learning, and completing my PhD Thesis.</description></item></channel></rss>